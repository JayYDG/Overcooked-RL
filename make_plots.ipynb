{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def parse_tensorboard(path, scalars):\n",
    "    \"\"\"returns a dictionary of pandas dataframes for each requested scalar\"\"\"\n",
    "    ea = event_accumulator.EventAccumulator(\n",
    "        path,\n",
    "        size_guidance={event_accumulator.SCALARS: 0},\n",
    "    )\n",
    "    _absorb_print = ea.Reload()\n",
    "    # make sure the scalars are in the event accumulator tags\n",
    "    assert all(\n",
    "        s in ea.Tags()[\"scalars\"] for s in scalars\n",
    "    ), \"some scalars were not found in the event accumulator\"\n",
    "    return {k: pd.DataFrame(ea.Scalars(k)) for k in scalars}\n",
    "\n",
    "def make_plot(dfs, labels, value='value', window=20):\n",
    "    fig, ax = plt.subplots()\n",
    "    for index, df in enumerate(dfs):\n",
    "        line = ax.plot(\n",
    "            df['step'], df[value], alpha=0.5, zorder=0, \n",
    "        )\n",
    "        temp_df = df.rolling(window, center=False).mean()\n",
    "        ax.plot(\n",
    "            temp_df['step'], temp_df[value], color=line[0].get_color(), zorder=1, label=labels[index]\n",
    "        )\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = ['charts/train_soup']\n",
    "\n",
    "with_centralized_critic = r'.\\runs\\fcnn_v2\\cramped_room\\fcnn_v2_3_num_envs\\events.out.tfevents.1713584415.overcooked-training.5534.0'\n",
    "\n",
    "with_decentralized_critic = r'.\\runs\\fcnn\\cramped_room\\fcnn_v1_3_num_envs\\events.out.tfevents.1713551795.overcooked-training.5519.0'\n",
    "\n",
    "with_centralized_critic_res = parse_tensorboard(with_centralized_critic, scalers)\n",
    "with_decentralized_critic_res = parse_tensorboard(with_decentralized_critic, scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    with_centralized_critic_res['charts/train_soup'],\n",
    "    with_decentralized_critic_res['charts/train_soup'],\n",
    "]\n",
    "fig, ax = make_plot(dfs, ['centralized_critic (default)', 'decentralized_critic'], value='value')\n",
    "ax.set_xlim([0, 2000])\n",
    "ax.set_ylim([0, 2])\n",
    "ax.legend()\n",
    "ax.set_xlabel('num_update')\n",
    "ax.set_ylabel('mean number of soup per episode')\n",
    "fig.savefig('critic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = ['charts/train_soup']\n",
    "\n",
    "without_rw = r'.\\runs\\fcnn_v2\\cramped_room\\fcnn_v2_3_num_envs\\events.out.tfevents.1713584415.overcooked-training.5534.0'\n",
    "\n",
    "with_rw = r'.\\runs\\fcnn_v2\\cramped_room\\fcnn_v2_3_num_envs_with_extra_rw\\events.out.tfevents.1713594167.with-extra-reward.8822.0'\n",
    "\n",
    "without_rw_res = parse_tensorboard(without_rw, scalers)\n",
    "with_rw_res = parse_tensorboard(with_rw, scalers)\n",
    "\n",
    "dfs = [\n",
    "    without_rw_res['charts/train_soup'],\n",
    "    with_rw_res['charts/train_soup'],\n",
    "]\n",
    "fig, ax = make_plot(dfs, ['without_rw (default)', 'with extra_rw'], value='value')\n",
    "ax.set_xlim([0, 5000])\n",
    "ax.set_ylim([0, 10])\n",
    "ax.legend()\n",
    "ax.set_xlabel('num_update')\n",
    "ax.set_ylabel('mean number of soup per episode')\n",
    "fig.savefig('extra_rw.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = ['charts/train_soup']\n",
    "\n",
    "without_time = r'.\\runs\\fcnn_v2\\cramped_room\\fcnn_v2_3_num_envs\\events.out.tfevents.1713584415.overcooked-training.5534.0'\n",
    "\n",
    "with_time_01 = r'.\\runs\\fcnn_v2\\cramped_room\\fcnn_v2_3_num_envs_with_time_punish_0.1\\events.out.tfevents.1713598269.overcook-runner.32077.0'\n",
    "\n",
    "with_time_1 = r'.\\runs\\fcnn_v2\\cramped_room\\fcnn_v2_3_num_envs_with_time_punish_1\\events.out.tfevents.1713598303.overcook-runner.32955.0'\n",
    "\n",
    "without_time_res = parse_tensorboard(without_time, scalers)\n",
    "with_time_01_res = parse_tensorboard(with_time_01, scalers)\n",
    "with_time_1_res = parse_tensorboard(with_time_1, scalers)\n",
    "\n",
    "dfs = [\n",
    "    without_time_res['charts/train_soup'],\n",
    "    with_time_01_res['charts/train_soup'],\n",
    "    with_time_1_res['charts/train_soup'],\n",
    "]\n",
    "fig, ax = make_plot(dfs, ['without_time_punish (default)', 'time_punish -0.1', 'time_punish -1'], value='value')\n",
    "ax.set_xlim([0, 3000])\n",
    "ax.set_ylim([0, 4])\n",
    "ax.legend()\n",
    "ax.set_xlabel('num_update')\n",
    "ax.set_ylabel('mean number of soup per episode')\n",
    "fig.savefig('time_punish.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = ['charts/train_soup']\n",
    "\n",
    "num_envs_3 = r'.\\runs\\fcnn_v2\\cramped_room\\fcnn_v2_3_num_envs\\events.out.tfevents.1713584415.overcooked-training.5534.0'\n",
    "\n",
    "num_envs_1 = r'.\\runs\\fcnn_v2\\cramped_room\\fcnn_v2_1_num_envs\\events.out.tfevents.1713631968.with-extra-reward.53789.0'\n",
    "\n",
    "num_envs_6 = r'.\\runs\\fcnn_v2\\cramped_room\\fcnn_v2_6_num_envs\\events.out.tfevents.1713628362.overcooked-training.1933271.0'\n",
    "\n",
    "num_envs_3_res = parse_tensorboard(num_envs_3, scalers)\n",
    "num_envs_1_res = parse_tensorboard(num_envs_1, scalers)\n",
    "num_envs_6_res = parse_tensorboard(num_envs_6, scalers)\n",
    "\n",
    "dfs = [\n",
    "    num_envs_3_res['charts/train_soup'],\n",
    "    num_envs_1_res['charts/train_soup'],\n",
    "    num_envs_6_res['charts/train_soup'],\n",
    "]\n",
    "fig, ax = make_plot(dfs, ['3 envs (default)', '1 envs', '6 envs'], value='value')\n",
    "ax.set_xlim([0, 3000])\n",
    "ax.set_ylim([0, 6])\n",
    "ax.legend()\n",
    "ax.set_xlabel('num_update')\n",
    "ax.set_ylabel('mean number of soup per episode')\n",
    "fig.savefig('num_envs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = ['charts/train_soup']\n",
    "\n",
    "normal = r'.\\runs\\fcnn_v2\\cramped_room\\fcnn_v2_3_num_envs\\events.out.tfevents.1713584415.overcooked-training.5534.0'\n",
    "\n",
    "fast = r'.\\runs\\fcnn_v2\\cramped_room\\fcnn_v2_3_num_envs_all_fast\\events.out.tfevents.1713613616.DESKTOP-I7N4NTT.2160.0'\n",
    "\n",
    "slow = r'.\\runs\\fcnn_v2\\cramped_room\\fcnn_v2_3_num_envs_all_slow\\events.out.tfevents.1713592644.overcooked-training.4077513.0'\n",
    "\n",
    "normal_res = parse_tensorboard(normal, scalers)\n",
    "fast_res = parse_tensorboard(fast, scalers)\n",
    "slow_res = parse_tensorboard(slow, scalers)\n",
    "\n",
    "dfs = [\n",
    "    normal_res['charts/train_soup'],\n",
    "    fast_res['charts/train_soup'],\n",
    "    slow_res['charts/train_soup'],\n",
    "]\n",
    "fig, ax = make_plot(dfs, ['Normal (default)', 'Fast', 'Slow'], value='value')\n",
    "ax.set_xlim([0, 5000])\n",
    "ax.set_ylim([0, 8])\n",
    "ax.legend()\n",
    "ax.set_xlabel('num_update')\n",
    "ax.set_ylabel('mean number of soup per episode')\n",
    "fig.savefig('lr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_with_std(df, ys):\n",
    "    # Create a new figure and axes object\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Iterate through the y-values to plot each one with its standard deviation\n",
    "    for y in ys:\n",
    "        # Extract the y values and their respective standard deviations\n",
    "        mean = df[y]\n",
    "        std = df[f'{y}_std']\n",
    "        step = df['num_update']\n",
    "\n",
    "        # Plot the mean line\n",
    "        ax.plot(step, mean, label=y)\n",
    "\n",
    "        # Fill between mean Â± std deviation\n",
    "        ax.fill_between(step, mean - std, mean + std, alpha=0.2)\n",
    "\n",
    "    # Adding a legend to the plot\n",
    "    ax.legend()\n",
    "\n",
    "    # Return the figure and axes object\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "from ppo_fcnn_v2 import helper_func_obs\n",
    "import torch\n",
    "device = 'cpu'\n",
    "\n",
    "def evaluate_policy(ppo_policy, env, num_episode=1000):\n",
    "    num_soups_made = np.zeros(num_episode)\n",
    "\n",
    "    for i in range(num_episode):\n",
    "\n",
    "        next_done = False\n",
    "\n",
    "        next_obs = env.reset()\n",
    "\n",
    "        reshaped_obs = helper_func_obs(next_obs[\"both_agent_obs\"])\n",
    "        while not next_done:\n",
    "\n",
    "            with torch.no_grad():\n",
    "                _, actions, _, _ = ppo_policy.get_action_and_value(\n",
    "                    reshaped_obs,\n",
    "                    deterministic=False,\n",
    "                )\n",
    "\n",
    "            next_obs, R, next_done, info = env.step(actions.view(-1).tolist())\n",
    "            reshaped_obs = helper_func_obs(next_obs[\"both_agent_obs\"])\n",
    "            num_soups_made[i] += int(R / 20)\n",
    "\n",
    "    return num_soups_made\n",
    "\n",
    "from overcooked_ai_py.mdp.overcooked_mdp import OvercookedGridworld\n",
    "from overcooked_ai_py.mdp.overcooked_env import OvercookedEnv\n",
    "from overcooked_ai_py.agents.agent import NNPolicy, AgentFromPolicy, AgentPair\n",
    "from overcooked_ai_py.agents.benchmarking import AgentEvaluator\n",
    "from overcooked_ai_py.visualization.state_visualizer import StateVisualizer\n",
    "import gym, os\n",
    "from tqdm import tqdm\n",
    "def evaluate_multiple_policies(base_policy, layout_name, num_episode=2):\n",
    "    # create envs\n",
    "    mdp = OvercookedGridworld.from_layout_name(\n",
    "        layout_name,\n",
    "        rew_shaping_params=None,\n",
    "    )\n",
    "    base_env = OvercookedEnv.from_mdp(\n",
    "        mdp, horizon=400, info_level=0\n",
    "    )\n",
    "\n",
    "    env = gym.make(\n",
    "            \"Overcooked-v0\",\n",
    "            base_env=base_env,\n",
    "            featurize_fn=base_env.featurize_state_mdp,\n",
    "        )\n",
    "    \n",
    "    model_dir = rf'./runs/fcnn_v2/{layout_name}/final'\n",
    "    param_files = [name for name in os.listdir(model_dir) if 'model.pt' in name]\n",
    "\n",
    "    final_res = {\n",
    "        'num_update':[],\n",
    "        layout_name: [],\n",
    "        layout_name+('_std'): [],\n",
    "    }\n",
    "    for param_file in tqdm(param_files, total=len(param_files)):\n",
    "        num_update = int(param_file.split('-')[0])\n",
    "        base_policy.load_model(os.path.join(model_dir, param_file))\n",
    "\n",
    "        num_soups_made = evaluate_policy(base_policy, env, num_episode=num_episode)\n",
    "\n",
    "        final_res['num_update'] += [num_update]\n",
    "        final_res[layout_name] += [np.mean(num_soups_made)]\n",
    "        final_res[layout_name+('_std')] += [np.std(num_soups_made)]\n",
    "    return pd.DataFrame(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppo_fcnn_v2 import Policy\n",
    "base_policy = Policy(100, 6, 'cpu')\n",
    "final_res = None\n",
    "for layout in ['cramped_room', 'asymmetric_advantages', 'coordination_ring', 'forced_coordination', 'counter_circuit_o_1order']:\n",
    "    print(layout)\n",
    "    res = evaluate_multiple_policies(base_policy, layout, num_episode=100)\n",
    "    if final_res is not None:\n",
    "        final_res = final_res.merge(res, on='num_update')\n",
    "    else:\n",
    "        final_res = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = final_res.sort_values('num_update')\n",
    "layout_names = ['cramped_room', 'asymmetric_advantages', 'coordination_ring', 'forced_coordination', 'counter_circuit_o_1order']\n",
    "fig, ax = plot_data_with_std(final_res, ys=layout_names)\n",
    "\n",
    "ax.hlines(y=7, xmax=5000, xmin=0, color='black', linestyles='--')\n",
    "\n",
    "ax.set_ylabel('Mean Number of Soup')\n",
    "ax.set_xlabel('Num Update')\n",
    "fig.savefig('final_res.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = ['charts/train_soup']\n",
    "\n",
    "cramped_room = r'.\\runs\\fcnn_v2\\cramped_room\\final\\events.out.tfevents.1713657918.overcooked-training.1423059.0'\n",
    "asymmetric_advantages = r'.\\runs\\fcnn_v2\\asymmetric_advantages\\final\\events.out.tfevents.1713657943.overcooked-training.1433505.0'\n",
    "coordination_ring = r'.\\runs\\fcnn_v2\\coordination_ring\\final\\events.out.tfevents.1713671226.with-extra-reward.32297.0'\n",
    "forced_coordination = r'.\\runs\\fcnn_v2\\forced_coordination\\final\\events.out.tfevents.1713658130.overcook-runner.101915.0'\n",
    "counter_circuit_o_1order = r'.\\runs\\fcnn_v2\\counter_circuit_o_1order\\final\\events.out.tfevents.1713658505.DESKTOP-I7N4NTT.36036.0'\n",
    "\n",
    "\n",
    "cramped_room = parse_tensorboard(cramped_room, scalers)\n",
    "asymmetric_advantages = parse_tensorboard(asymmetric_advantages, scalers)\n",
    "coordination_ring = parse_tensorboard(coordination_ring, scalers)\n",
    "forced_coordination = parse_tensorboard(forced_coordination, scalers)\n",
    "counter_circuit_o_1order = parse_tensorboard(counter_circuit_o_1order, scalers)\n",
    "\n",
    "dfs = [\n",
    "    cramped_room['charts/train_soup'],\n",
    "    asymmetric_advantages['charts/train_soup'],\n",
    "    coordination_ring['charts/train_soup'],\n",
    "    forced_coordination['charts/train_soup'],\n",
    "    counter_circuit_o_1order['charts/train_soup'],\n",
    "]\n",
    "\n",
    "for index, df in enumerate(dfs):\n",
    "    print(layout_names[index])\n",
    "    print(df[df['value'] > 0]['step'][:5].to_list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
